from vllm import LLM, SamplingParams
import torch
import numpy as np
import pyaudio
from TTS.api import TTS  # âœ… VITS for Real-time Speech

# âœ… **Set up Model Configuration**
MODEL_NAME = "HuggingFaceH4/llama-chat-hf"  # ðŸ”¥ Change this to Llamac-chat-HF model

# âœ… **Use vLLM for Super-Fast Inference**
llm = LLM(
    model=MODEL_NAME,
    tensor_parallel_size=1,  # Set according to your GPU setup
    gpu_memory_utilization=0.9,  # ðŸ”¥ Optimize GPU usage
    dtype="bfloat16" if torch.cuda.is_bf16_supported() else "float16"
)

# âœ… **Configure Sampling for Faster Responses**
sampling_params = SamplingParams(
    temperature=0.7,
    top_p=0.9,
    max_tokens=128,  # âœ… Shorten response time
    repetition_penalty=1.1
)

# âœ… **Load VITS TTS Model**
tts = TTS(model_name="tts_models/en/ljspeech/vits").to("cuda" if torch.cuda.is_available() else "cpu")

# âœ… **Generate AI Response with vLLM**
def generate_response(user_input):
    try:
        prompt = f"### Instruction:\nYou are a helpful AI assistant.\n\n### User:\n{user_input}\n\n### AI Assistant:"

        # ðŸ”¥ **Use vLLM for Fast Inference**
        outputs = llm.generate([prompt], sampling_params)
        ai_response = outputs[0].outputs[0].text.strip()

        # âœ… **Convert Text to Speech**
        audio_samples = tts.tts(text=ai_response)
        audio_samples = np.array(audio_samples, dtype=np.float32).flatten()  # ðŸ”¥ Fix: Flatten tensor
        
        return ai_response, audio_samples

    except Exception as e:
        return f"ðŸ¤– Error: {str(e)}", None

# âœ… **Real-time Audio Playback**
def play_audio_realtime(audio_samples, sample_rate=22050):
    p = pyaudio.PyAudio()
    stream = p.open(format=pyaudio.paFloat32, channels=1, rate=sample_rate, output=True)
    stream.write(audio_samples.tobytes())
    stream.stop_stream()
    stream.close()
    p.terminate()

# âœ… **Simple Chat Loop**
if __name__ == "__main__":
    while True:
        user_input = input("You: ")
        if user_input.lower() in ["exit", "quit", "bye"]:
            print("ðŸ¤– Goodbye!")
            break
        
        response, audio_samples = generate_response(user_input)
        print(f"AI: {response}")

        # âœ… **Play AI Speech in Real-Time**
        if audio_samples is not None:
            play_audio_realtime(audio_samples)
